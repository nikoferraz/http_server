# Nginx Configuration for HTTP Server Canary Deployment
# Handles traffic splitting between stable (v1) and canary (v2-optimized) versions

upstream backend_stable {
    least_conn;

    server http-server-stable:8080 max_fails=3 fail_timeout=10s;
    server http-server-stable:8080 max_fails=3 fail_timeout=10s;
    server http-server-stable:8080 max_fails=3 fail_timeout=10s;

    # Keep connections alive to leverage HTTP keep-alive
    keepalive 64;
    keepalive_timeout 60s;
    keepalive_requests 100;
}

upstream backend_canary {
    least_conn;

    server http-server-canary:8080 max_fails=3 fail_timeout=10s;

    keepalive 64;
    keepalive_timeout 60s;
    keepalive_requests 100;
}

# Traffic splitting configuration
# Adjust the percentages during deployment phases:
# Phase 1: 1% canary, 99% stable
# Phase 2: 5% canary, 95% stable
# Phase 3: 25% canary, 75% stable
# Phase 4: 75% canary, 25% stable
# Phase 5: 100% canary, 0% stable

split_clients "${remote_addr}${http_user_agent}${date_gmt}" $backend {
    # Current phase: Phase 1 (1% canary)
    1%     backend_canary;
    *      backend_stable;
}

# Alternative: Debug mode - route based on header
map $http_x_force_canary $backend_debug {
    "true"  backend_canary;
    default $backend;
}

# Metrics endpoint for monitoring
upstream metrics {
    server localhost:9100;
}

# Main server configuration
server {
    listen 80 default_server;
    listen [::]:80 default_server;
    server_name _;

    # Logging
    access_log /var/log/nginx/access.log combined;
    error_log /var/log/nginx/error.log warn;

    # Log format with canary tracking
    log_format canary_log '$remote_addr - $remote_user [$time_local] '
                         '"$request" $status $body_bytes_sent '
                         '"$http_referer" "$http_user_agent" '
                         'backend=$backend response_time=$upstream_response_time '
                         'version=$http_x_backend_version cache=$http_x_cache_status';

    # Client request timeouts
    client_body_timeout 10s;
    client_header_timeout 10s;
    send_timeout 30s;

    # Buffer settings
    client_body_buffer_size 10m;
    proxy_buffering on;
    proxy_buffer_size 4k;
    proxy_buffers 8 4k;
    proxy_busy_buffers_size 8k;

    # Main request routing
    location / {
        proxy_pass http://$backend;
        proxy_http_version 1.1;

        # Headers forwarding
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        proxy_set_header X-Forwarded-Proto $scheme;
        proxy_set_header X-Forwarded-Host $server_name;
        proxy_set_header X-Forwarded-Port $server_port;

        # Canary tracking header
        proxy_set_header X-Canary-Backend $backend;
        proxy_set_header X-Canary-Request-Time $msec;

        # Keep-Alive settings for connection reuse
        proxy_set_header Connection "";
        proxy_http_version 1.1;

        # Cache settings for the backend response
        proxy_cache_use_stale error timeout invalid_header updating;
        proxy_cache_bypass $http_pragma $http_authorization;
        add_header X-Cache-Status $upstream_cache_status;

        # Timeouts
        proxy_connect_timeout 5s;
        proxy_send_timeout 30s;
        proxy_read_timeout 30s;
        proxy_request_buffering off;

        # Don't modify location headers
        proxy_redirect off;

        # Error handling
        proxy_next_upstream error timeout invalid_header http_500 http_502 http_503;
        proxy_next_upstream_tries 2;
        proxy_next_upstream_timeout 10s;
    }

    # Health check endpoints - accessible from both backends
    location /health/ {
        access_log off;

        proxy_pass http://$backend;
        proxy_http_version 1.1;
        proxy_set_header Connection "";

        proxy_connect_timeout 3s;
        proxy_read_timeout 5s;
    }

    # Liveness probe - returns 200 if nginx is up
    location /health/alive {
        access_log off;
        add_header Content-Type "application/json";
        return 200 '{"status":"UP","service":"nginx-proxy"}';
    }

    # Readiness probe - checks if backends are available
    location /health/ready {
        access_log off;

        # Try both backends for readiness
        proxy_pass http://$backend;
        proxy_http_version 1.1;
        proxy_set_header Connection "";

        proxy_connect_timeout 2s;
        proxy_read_timeout 3s;
    }

    # Metrics endpoint for Prometheus
    location /metrics {
        proxy_pass http://metrics;
        access_log off;
        proxy_http_version 1.1;
        proxy_set_header Connection "";
    }

    # Deployment status endpoint
    location /deployment/status {
        access_log off;
        default_type application/json;

        return 200 '{"stable":{"replicas":3,"version":"v1-stable"},"canary":{"replicas":1,"version":"v2-optimized"},"traffic":{"stable":99,"canary":1},"phase":"1"}';
    }

    # Deny access to sensitive paths
    location ~ /\.git/ {
        deny all;
    }

    location ~ /\.env {
        deny all;
    }

    # Catch-all for 404
    location ~ /\. {
        deny all;
        access_log off;
    }
}

# HTTPS server configuration (for production)
server {
    listen 443 ssl http2 default_server;
    listen [::]:443 ssl http2 default_server;
    server_name _;

    # SSL configuration
    ssl_certificate /etc/nginx/ssl/cert.pem;
    ssl_certificate_key /etc/nginx/ssl/key.pem;
    ssl_protocols TLSv1.2 TLSv1.3;
    ssl_ciphers HIGH:!aNULL:!MD5;
    ssl_prefer_server_ciphers on;
    ssl_session_cache shared:SSL:10m;
    ssl_session_timeout 10m;

    # HSTS header
    add_header Strict-Transport-Security "max-age=31536000; includeSubDomains" always;

    access_log /var/log/nginx/access_ssl.log combined;
    error_log /var/log/nginx/error.log warn;

    # Client request timeouts
    client_body_timeout 10s;
    client_header_timeout 10s;
    send_timeout 30s;

    # Main request routing (same as HTTP)
    location / {
        proxy_pass http://$backend;
        proxy_http_version 1.1;

        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        proxy_set_header X-Forwarded-Proto https;
        proxy_set_header X-Forwarded-Host $server_name;
        proxy_set_header X-Forwarded-Port 443;

        proxy_set_header X-Canary-Backend $backend;
        proxy_set_header Connection "";
        proxy_http_version 1.1;

        proxy_connect_timeout 5s;
        proxy_send_timeout 30s;
        proxy_read_timeout 30s;

        proxy_redirect off;
        proxy_next_upstream error timeout invalid_header http_500 http_502 http_503;
        proxy_next_upstream_tries 2;
    }

    # Health check endpoints
    location /health/ {
        access_log off;
        proxy_pass http://$backend;
        proxy_http_version 1.1;
        proxy_set_header Connection "";
        proxy_connect_timeout 3s;
        proxy_read_timeout 5s;
    }

    # Metrics endpoint
    location /metrics {
        proxy_pass http://metrics;
        access_log off;
        proxy_http_version 1.1;
        proxy_set_header Connection "";
    }
}

# Redirect HTTP to HTTPS (optional, enable for production)
# server {
#     listen 80;
#     listen [::]:80;
#     server_name _;
#     return 301 https://$host$request_uri;
# }
